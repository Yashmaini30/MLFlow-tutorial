{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. hyperparemter sweep\n",
    "2. Comparethe result  of the runs in the MLflow  UI\n",
    "3. Choose best run and register model\n",
    "4. Deploy the model on Rest API\n",
    "5. Make a container and upload to cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK,Trials,fmin,hp,tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load the dataset\n",
    "data=pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.046</td>\n",
       "      <td>17.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.99319</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.048</td>\n",
       "      <td>39.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.99420</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.052</td>\n",
       "      <td>69.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.99580</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.054</td>\n",
       "      <td>67.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>0.99848</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>32.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99500</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.99125</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.030</td>\n",
       "      <td>22.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.99140</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.68</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.037</td>\n",
       "      <td>24.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.98986</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.33</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.026</td>\n",
       "      <td>31.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.98980</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>11.633333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.053</td>\n",
       "      <td>32.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3918 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "2399            6.1              0.16         0.24             1.4      0.046   \n",
       "1604            6.7              0.41         0.01             2.8      0.048   \n",
       "2818            6.0              0.11         0.47            10.6      0.052   \n",
       "2892            6.7              0.42         0.46             9.7      0.054   \n",
       "49              6.9              0.19         0.35             5.0      0.067   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "2372            6.0              0.33         0.18             3.0      0.036   \n",
       "2133            8.3              0.24         0.27             2.1      0.030   \n",
       "4802            5.8              0.28         0.34             2.2      0.037   \n",
       "4734            5.5              0.16         0.31             1.2      0.026   \n",
       "266             6.9              0.32         0.26             8.3      0.053   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "2399                 17.0                  77.0  0.99319  3.66       0.57   \n",
       "1604                 39.0                 137.0  0.99420  3.24       0.35   \n",
       "2818                 69.0                 148.0  0.99580  2.91       0.34   \n",
       "2892                 67.0                 234.0  0.99848  3.23       0.50   \n",
       "49                   32.0                 150.0  0.99500  3.36       0.48   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "2372                  5.0                  85.0  0.99125  3.28       0.40   \n",
       "2133                 22.0                 162.0  0.99140  2.99       0.68   \n",
       "4802                 24.0                 125.0  0.98986  3.36       0.33   \n",
       "4734                 31.0                  68.0  0.98980  3.33       0.44   \n",
       "266                  32.0                 180.0  0.99650  3.25       0.51   \n",
       "\n",
       "        alcohol  quality  \n",
       "2399  10.300000        6  \n",
       "1604   9.500000        5  \n",
       "2818   9.300000        4  \n",
       "2892   9.000000        5  \n",
       "49     9.800000        5  \n",
       "...         ...      ...  \n",
       "2372  11.500000        4  \n",
       "2133  11.900000        6  \n",
       "4802  12.800000        8  \n",
       "4734  11.633333        6  \n",
       "266    9.200000        6  \n",
       "\n",
       "[3918 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### split the data into train, validation and test set\n",
    "\n",
    "train,test=train_test_split(data,test_size=0.2)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train.drop(\"quality\",axis=1).values\n",
    "train_y=train[\"quality\"].values.ravel()\n",
    "\n",
    "# test datset\n",
    "test_x=test.drop(\"quality\",axis=1).values\n",
    "test_y=test[\"quality\"].values.ravel()\n",
    "\n",
    "## split this train data into train and validation\n",
    "train_x,valid_x,train_y,valid_y=train_test_split(train_x,train_y,test_size=0.2,random_state=42)\n",
    "\n",
    "signature=infer_signature(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params, epochs, train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
    "\n",
    "    ## model architecture\n",
    "    mean = np.mean(train_x, axis=0)\n",
    "    var = np.var(train_x, axis=0)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.Input([train_x.shape[1]]),\n",
    "        keras.layers.Normalization(mean=mean, variance=var),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    ## compile the model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(\n",
    "            learning_rate=params[\"lr\"],\n",
    "            momentum=params[\"momentum\"]\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    ## train the model with mlflow tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_x, train_y, validation_data=(valid_x, valid_y),\n",
    "                  epochs=epochs, batch_size=32)\n",
    "\n",
    "        ## evaluate the model\n",
    "        eval_result = model.evaluate(test_x, test_y)  # Now test_x is passed correctly\n",
    "        eval_rmse = eval_result[1]\n",
    "\n",
    "        ## log the parameters and metrics\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\"rmse\": eval_rmse})\n",
    "\n",
    "        ## log the model\n",
    "        mlflow.tensorflow.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "        return {\"loss\": eval_rmse, \"status\": STATUS_OK, \"model\": model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    ## mlflow will track the parameters and results for each run\n",
    "    result=train_model(\n",
    "        params=params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    \"lr\":hp.loguniform(\"lr\",np.log(0.00001),np.log(0.1)),\n",
    "    \"momentum\":hp.uniform(\"momentum\",0.1,0.9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 14:33:22 INFO mlflow.tracking.fluent: Experiment with name 'Wine-quality' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 375ms/step - loss: 39.8293 - root_mean_squared_error: 6.3110\n",
      "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40.9332 - root_mean_squared_error: 6.3978   \n",
      "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40.2339 - root_mean_squared_error: 6.3428\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 40.2102 - root_mean_squared_error: 6.3409 - val_loss: 37.1181 - val_root_mean_squared_error: 6.0925\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 33.5193 - root_mean_squared_error: 5.7896\n",
      "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 36.1704 - root_mean_squared_error: 6.0141\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35.8956 - root_mean_squared_error: 5.9911 - val_loss: 33.5639 - val_root_mean_squared_error: 5.7934\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 33.2009 - root_mean_squared_error: 5.7620\n",
      "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 33.3153 - root_mean_squared_error: 5.7719\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.8022 - root_mean_squared_error: 5.7271 - val_loss: 30.3702 - val_root_mean_squared_error: 5.5109\n",
      "\n",
      "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 28.7381 - root_mean_squared_error: 5.3608\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29.4651 - root_mean_squared_error: 5.4281 \n",
      "\n",
      "Epoch 1/3                                                                     \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 446ms/step - loss: 35.4023 - root_mean_squared_error: 5.9500\n",
      "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.5771 - root_mean_squared_error: 5.8801   \n",
      "\u001b[1m74/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33.9755 - root_mean_squared_error: 5.8286\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 33.6463 - root_mean_squared_error: 5.8001 - val_loss: 29.0006 - val_root_mean_squared_error: 5.3852\n",
      "\n",
      "Epoch 2/3                                                                     \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 29.1993 - root_mean_squared_error: 5.4036\n",
      "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.2696 - root_mean_squared_error: 5.3169 \n",
      "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27.6743 - root_mean_squared_error: 5.2602\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.5147 - root_mean_squared_error: 5.2449 - val_loss: 23.5509 - val_root_mean_squared_error: 4.8529\n",
      "\n",
      "Epoch 3/3                                                                     \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 20.6005 - root_mean_squared_error: 4.5388\n",
      "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.2508 - root_mean_squared_error: 4.8215 \n",
      "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.5905 - root_mean_squared_error: 4.7523\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.4043 - root_mean_squared_error: 4.7325 - val_loss: 19.0925 - val_root_mean_squared_error: 4.3695\n",
      "\n",
      "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 19.1577 - root_mean_squared_error: 4.3770\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18.1391 - root_mean_squared_error: 4.2586 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 446ms/step - loss: 40.1263 - root_mean_squared_error: 6.3345\n",
      "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 37.2656 - root_mean_squared_error: 6.1041 \n",
      "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36.7948 - root_mean_squared_error: 6.0652  \n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 36.6406 - root_mean_squared_error: 6.0524 - val_loss: 31.8365 - val_root_mean_squared_error: 5.6424\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 30.9530 - root_mean_squared_error: 5.5635\n",
      "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 30.8152 - root_mean_squared_error: 5.5506\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30.2041 - root_mean_squared_error: 5.4950 - val_loss: 26.3897 - val_root_mean_squared_error: 5.1371\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 26.6631 - root_mean_squared_error: 5.1636\n",
      "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 25.2895 - root_mean_squared_error: 5.0287\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24.8456 - root_mean_squared_error: 4.9840 - val_loss: 21.8405 - val_root_mean_squared_error: 4.6734\n",
      "\n",
      "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 20.5554 - root_mean_squared_error: 4.5338\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.7487 - root_mean_squared_error: 4.5550 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 335ms/step - loss: 42.7591 - root_mean_squared_error: 6.5390\n",
      "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0736 - root_mean_squared_error: 2.8318    \n",
      "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.8358 - root_mean_squared_error: 2.2238\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.6096 - root_mean_squared_error: 2.1769 - val_loss: 0.7735 - val_root_mean_squared_error: 0.8795\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 1.0511 - root_mean_squared_error: 1.0252\n",
      "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.7021 - root_mean_squared_error: 0.8366\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6723 - root_mean_squared_error: 0.8189 - val_loss: 0.5567 - val_root_mean_squared_error: 0.7461\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.5888 - root_mean_squared_error: 0.7673\n",
      "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.5846 - root_mean_squared_error: 0.7644\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5805 - root_mean_squared_error: 0.7618 - val_loss: 0.5297 - val_root_mean_squared_error: 0.7278\n",
      "\n",
      "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2044 - root_mean_squared_error: 0.4521\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4202 - root_mean_squared_error: 0.6461 \n",
      "\n",
      "100%|██████████| 4/4 [00:27<00:00,  6.99s/trial, best loss: 0.6874974966049194]\n",
      "Best parameters: {'lr': np.float64(0.021763457989871716), 'momentum': np.float64(0.7673633219885597)}\n",
      "Best loss: 0.6874974966049194\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    ## conduct the hyperparameter search\n",
    "    trials=Trials()\n",
    "    best=fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    ## get the best parameters\n",
    "    best_run=sorted(trials.results,key=lambda x:x[\"loss\"])[0]\n",
    "\n",
    "    ##log the best parameters,loss and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metrics({\"rmse\":best_run[\"loss\"]})\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"],\"model\",signature=signature)\n",
    "\n",
    "    ## print out the best parameters and corresponding loss\n",
    "    print(\"Best parameters:\",best)\n",
    "    print(\"Best loss:\",best_run[\"loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
